{"cells":[{"cell_type":"markdown","metadata":{"id":"-eMoRFzE7sVf"},"source":["## Training for ResNet18 - 128\n","with 128 x 128 input size and modified conv1 layer"]},{"cell_type":"markdown","metadata":{},"source":["*if using google drive, run following two cells*"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2340,"status":"ok","timestamp":1710388655459,"user":{"displayName":"Haoyu Zhou","userId":"17886401950307679344"},"user_tz":-660},"id":"mp1vAm1j79O0","outputId":"828a6a25-676c-4808-ebd0-914c96861b46"},"outputs":[],"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","project_dir = '/content/drive/MyDrive/master_courses/BIDH5001 Capstone/Project/\\\n","deep-classification'\n","os.chdir(project_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4764,"status":"ok","timestamp":1710387066856,"user":{"displayName":"Haoyu Zhou","userId":"17886401950307679344"},"user_tz":-660},"id":"BkyMECYW9UXl","outputId":"3964ab35-d720-494f-ced5-9a5919a582e1"},"outputs":[],"source":["%pip install pydicom    "]},{"cell_type":"markdown","metadata":{},"source":["imports, initiating dataloaders"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3662,"status":"ok","timestamp":1710388660985,"user":{"displayName":"Haoyu Zhou","userId":"17886401950307679344"},"user_tz":-660},"id":"gZ4IgZNy7sVj"},"outputs":[],"source":["# imports\n","import datetime\n","import time\n","import warnings\n","import torch\n","import config\n","from dataio.dataloader import create_dataloader\n","from networks.resnet_classifier import resnet18_128_classifier\n","from training.evaluation import AccuracyEvaluator, LossEvaluator\n","from training.utility.progress_bar import ProgressBar\n","from training.utility.early_stopper import ValLoss as EarlyStopper\n","\n","# whenever possible, use cuda instead of cpu\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")\n","    warnings.warn(\"cuda is using CPU, this can be very slow\")\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# paths to save and load state dictionary\n","import os\n","import re\n","\n","load_sd = False\n","save_sd = False\n","\n","bin_path = \"bin\"\n","assert os.path.isdir(bin_path)\n","sd_files = [\n","    filename for filename in os.listdir(bin_path)\n","    if re.match(r'res18_128_state_[0-9]{2}-[0-9]{2}\\.pkl', filename)]\n","sd_files.sort(reverse=True)\n","sd_load_filename = sd_files[0] if len(sd_files) > 0 else None\n","sd_save_filename = f\"res18_128_state_{datetime.datetime.now().strftime('%m-%d')}.pkl\"\n","sd_load_path = os.path.join(bin_path, sd_load_filename) \\\n","    if sd_load_filename is not None else None\n","sd_save_path = os.path.join(bin_path, sd_save_filename)"]},{"cell_type":"markdown","metadata":{},"source":["preparing the training:\n","1. read dicoms and labels from configuration and tracking table, initiate dataloaders\n","2. set up criterions and optimizers, training parameters"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# reading from configurations\n","dicoms = config.tracking_table['dicom_path'].to_list()\n","labels = config.tracking_table['label'].astype('int16').to_list()\n","\n","# initiate the dataloaders\n","dataloader_dict = create_dataloader(\n","    dicoms, labels,\n","    dicom_dir = config.dicom_dir,\n","    batch_size = 16,\n","    validation_size = config.validation_size,\n","    test_size = config.test_size,\n","    img_size=(128, 128)\n",")\n","training_dataloader, validation_dataloader, test_dataloader = \\\n","    (dataloader_dict.get(key) for key in ('training_dataloader', 'validation_dataloader', 'test_dataloader'))"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":694,"status":"ok","timestamp":1710388665235,"user":{"displayName":"Haoyu Zhou","userId":"17886401950307679344"},"user_tz":-660},"id":"mNMjQKN57sVk"},"outputs":[],"source":["# some settings, move to config in future\n","learning_rate = 0.0005 # 0.00005, originally without lr scheduler\n","n_epoches = 15\n","min_epoches = 7\n","starting_epoch = 0\n","\n","# the classifier model\n","model = resnet18_128_classifier\n","# load state dict into \n","if load_sd and sd_load_path:\n","    state_dict = torch.load(sd_load_path)\n","    model.load_state_dict(state_dict)\n","\n","# optimizers\n","loss_function = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","# scheduler = torch.optim.lr_scheduler.OneCycleLR(\n","#     optimizer, max_lr=learning_rate,\n","#     steps_per_epoch=len(training_dataloader), epochs=n_epoches,\n","#     )\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer, 'min', factor=0.25, patience=1,\n","    # threshold=0.05, threshold_mode='rel',\n","    min_lr = learning_rate / 32,\n","    cooldown=7,\n",")\n","earlystopper = EarlyStopper(tolerance=3, target=0.25, delta=0.001)\n","\n","# accuracy and loss evaluators\n","training_loss = LossEvaluator(loss_function)\n","validation_loss = LossEvaluator(loss_function)\n","validation_accuracy = AccuracyEvaluator()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# to continue training for n_epoches\n","learning_rate = 0.001\n","n_epoches = 3"]},{"cell_type":"markdown","metadata":{"id":"lj81jJj17sVl"},"source":["training for resnet18 image quality classifier"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch # 1\n","train loss: 0.632          validation loss: 1.339          validation accuracy: 14.29 %\n","precision: -1          recall: -1          f1: -1.0\n","duration: 25.23 s          learning rate: 0.0008\n","---------------------------------------------------------------------------\n","epoch # 2\n","train loss: 0.376          validation loss: 1.436          validation accuracy: 14.29 %\n","precision: -1          recall: -1          f1: -1.0\n","duration: 24.63 s          learning rate: 0.0008\n","---------------------------------------------------------------------------\n","epoch # 3\n","train loss: 0.283          validation loss: 1.815          validation accuracy: 14.29 %\n","precision: -1          recall: -1          f1: -1.0\n","duration: 24.67 s          learning rate: 0.0002\n","---------------------------------------------------------------------------\n","epoch # 4\n","train loss: 0.116          validation loss: 1.586          validation accuracy: 14.29 %\n","precision: -1          recall: -1          f1: -1.0\n","duration: 24.68 s          learning rate: 0.0002\n","---------------------------------------------------------------------------\n","epoch # 5\n","train loss: 0.036          validation loss: 1.37          validation accuracy: 14.29 %\n","precision: -1          recall: -1          f1: -1.0\n","duration: 25.93 s          learning rate: 0.0002\n","---------------------------------------------------------------------------\n","epoch # 6\n","train loss: 0.02          validation loss: 1.417          validation accuracy: 14.29 %\n","precision: -1          recall: -1          f1: -1.0\n","duration: 25.02 s          learning rate: 0.0002\n","---------------------------------------------------------------------------\n","epoch # 7\n","train loss: 0.012          validation loss: 1.478          validation accuracy: 14.29 %\n","precision: -1          recall: -1          f1: -1.0\n","duration: 25.12 s          learning rate: 0.0002\n","---------------------------------------------------------------------------\n"]}],"source":["# evaluators for training/validation loss and accuracy\n","# training_loss = LossEvaluator(loss_function)\n","# validation_loss = LossEvaluator(loss_function)\n","# validation_accuracy = AccuracyEvaluator()\n","\n","# training epoches loop\n","for epoch in range(n_epoches):\n","    current_epoch = epoch + 1 + starting_epoch\n","    print(f'epoch # {current_epoch}')\n","    progress = ProgressBar(len(training_dataloader) + len(validation_dataloader))\n","    epoch_start_time = time.time()\n","    # reset pred and actual labels after each epoch\n","    validation_accuracy.reset()\n","    training_loss.reset()\n","    validation_loss.reset()\n","    # training network\n","    for images, labels in training_dataloader:\n","        # images = images.to(torch.float32)\n","        # labels = labels.to(torch.float32)\n","        labels_pred = model(images)\n","        # train loss\n","        loss_training = loss_function(labels_pred, labels)\n","        training_loss.append_loss(loss_training.item())\n","        # backpropagation\n","        optimizer.zero_grad()\n","        loss_training.backward()\n","        optimizer.step()\n","        progress.step()\n","    # validating network\n","    for images, labels in validation_dataloader:\n","        # images = images.to(torch.float32)\n","        # labels = labels.to(torch.float32)\n","        labels_pred = model(images)\n","        loss_validation = loss_function(labels_pred, labels)\n","        validation_loss.append_loss(loss_validation.item())\n","        validation_accuracy.append(labels_pred, labels)\n","        progress.step()\n","    epoch_end_time = time.time()\n","    # step scheduler\n","    scheduler.step(validation_loss.value())\n","    # step early stopper\n","    earlystopper.step(validation_loss.value())\n","    print(\n","        f'train loss: {training_loss}  \\\n","        validation loss: {validation_loss}  \\\n","        validation accuracy: {validation_accuracy}')\n","    print(\n","        f'precision: {round(validation_accuracy.precision(), 3)}  \\\n","        recall: {round(validation_accuracy.recall(), 3)}  \\\n","        f1: {round(validation_accuracy.f1(), 3)}')\n","    # the evaluators have __str__\n","    print(\n","        f'duration: {round(epoch_end_time - epoch_start_time, 2)} s  \\\n","        learning rate: {round(scheduler.get_last_lr()[0], 9)}')\n","    print('-'*75)\n","    if earlystopper.stop() and current_epoch > min_epoches:\n","        print('early stopper triggered, break')\n","        break\n","    \n","\n","# update the starting epoch number\n","starting_epoch += epoch"]},{"cell_type":"markdown","metadata":{},"source":["save state dict"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# save model state_dicts to target path\n","if save_sd:\n","    torch.save(model.state_dict(), sd_save_path)\n","    print(f'state dict saved to path: {sd_save_path}')"]},{"cell_type":"markdown","metadata":{},"source":["(debugging the network)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["[torch.argmax(lbl).item() for lbl in validation_accuracy.labels_actual_raw]"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["[1,\n"," 1,\n"," 1,\n"," 1,\n"," 2,\n"," 2,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["validation_accuracy.labels_actual"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.Tensor(1) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sample_image = torch.randn(1, 1, )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["images.shape\n","# model(images)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# resnet18_128_classifier.layer1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["resnet18_128_classifier.conv1(sample_input)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["resnet18_128_classifier.bn1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## debugging\n","sample_input = torch.randn(1,1,128,128)\n","sample_1 = resnet18_128_classifier.conv1(sample_input)\n","sample_2 = resnet18_128_classifier.bn1(sample_1)\n","sample_1.shape, sample_2.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sample_1.size()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sample_input = torch.randn(1,1,128,128)\n","resnet18_128_classifier(sample_input).shape\n","resnet18_128_classifier()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from networks.resnet_classifier import resnet18_classifier\n","sample_input = torch.randn(1,1,64,64)\n","sample_1 = resnet18_classifier.conv1(sample_input)\n","sample_2 = resnet18_classifier.bn1(sample_1)\n","sample_1.shape, sample_2.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sample_1.size()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sample_input = torch.randn(1,1,64,64)\n","resnet18_classifier(sample_input).shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(validation_loss.labels_actual_raw)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import datetime\n","state_dict_save_path = f\"bin/res18_state_{datetime.datetime.now().strftime('%m-%d')}\"\n","state_dict_save_path"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import datetime\n","state_dict_save_path = f\"bin/res18_state_{datetime.datetime.now().strftime('%m-%d')}.pkl\"\n","torch.save(model.state_dict(), state_dict_save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["validation_accuracy._tfpn()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sum([len(training_dataloader), len(validation_dataloader), len(test_dataloader)])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["validation_pred_labels = [torch.argmax(lbl).item() for lbl in validation_accuracy.labels_pred_raw]\n","validation_actual_labels = [torch.argmax(lbl).item() for lbl in validation_accuracy.labels_actual_raw]\n","sum(validation_pred_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n_total = len(validation_actual_labels)\n","n_correct = 0\n","for pred_label, actual_label in zip(validation_pred_labels, validation_actual_labels):\n","    if pred_label == actual_label:\n","        n_correct += 1\n","n_correct / n_total"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["validation_accuracy.labels_pred_raw[:3]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["validation_accuracy.accuracy()"]},{"cell_type":"markdown","metadata":{},"source":["calculate test set loss and accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# evaluators for test loss and accuracy\n","test_loss = LossEvaluator(criterion=loss_function)\n","test_accuracy = AccuracyEvaluator()\n","\n","# iterate through test dataloader\n","for images, labels in test_dataloader:\n","    images = images.to(torch.float32)\n","    labels = labels.to(torch.float32)\n","    labels_pred = model(images)\n","    loss = loss_function(labels_pred, labels)\n","    test_loss.append_loss(loss)\n","    test_accuracy.append(labels_pred, labels)\n","print(f'test loss: {test_loss}\\\n","    test accuracy: {test_accuracy}')\n","print(\n","    f'precision: {round(test_accuracy.precision(), 3)}  \\\n","    recall: {round(test_accuracy.recall(), 3)}  \\\n","    f1: {round(test_accuracy.f1(), 3)}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# function shows saliency map\n","def calculate_saliency_map(model, image, target_class):\n","\n","    \"\"\"\n","    Calculates the saliency map for a given image and target class.\n","\n","    Args:\n","    model: A PyTorch model.\n","    image: A PyTorch tensor containing the image.\n","    target_class: The target class.\n","\n","    Returns:\n","    numpy array containing the saliency map.\n","    \"\"\"\n","\n","    # Forward pass the image through the model.\n","    output = model(image)\n","    # Get the gradient of the output with respect to the input image.\n","    # gradient = torch.autograd.grad(output[0][target_class], image[0])\n","    gradient = torch.autograd.grad(\n","        output, image, grad_outputs=target_class.view(1,-1),\n","        allow_unused=True)[0][0]\n","    # Calculate the absolute value of the gradient.\n","    # saliency_map = torch.abs(gradient)\n","    saliency_map = torch.norm(gradient)\n","    # Normalize the saliency map.\n","    saliency_map = saliency_map / torch.max(saliency_map)\n","    saliency_map_np = saliency_map.detach().numpy()\n","    return saliency_map_np"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["gradient = torch.autograd.grad(output, image, grad_outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","image = images[0][0]\n","plt.imshow(image, cmap='binary_r')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tempfile\n","for images in test_dataloader.view()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(validation_accuracy.labels_actual_raw)"]},{"cell_type":"markdown","metadata":{},"source":["## Appendix\n","additional details about the model"]},{"cell_type":"markdown","metadata":{},"source":["structure of the resnet_18 model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["isinstance(model, torch.nn.Module)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}
