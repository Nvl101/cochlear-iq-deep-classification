{"cells":[{"cell_type":"markdown","metadata":{"id":"-eMoRFzE7sVf"},"source":["## Training for ResNet18"]},{"cell_type":"markdown","metadata":{},"source":["*if using google drive, run following two cells*"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2340,"status":"ok","timestamp":1710388655459,"user":{"displayName":"Haoyu Zhou","userId":"17886401950307679344"},"user_tz":-660},"id":"mp1vAm1j79O0","outputId":"828a6a25-676c-4808-ebd0-914c96861b46"},"outputs":[],"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","project_dir = '/content/drive/MyDrive/master_courses/BIDH5001 Capstone/Project/\\\n","deep-classificataon'\n","os.chdir(project_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4764,"status":"ok","timestamp":1710387066856,"user":{"displayName":"Haoyu Zhou","userId":"17886401950307679344"},"user_tz":-660},"id":"BkyMECYW9UXl","outputId":"3964ab35-d720-494f-ced5-9a5919a582e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pydicom in /usr/local/lib/python3.10/dist-packages (2.4.4)\n"]}],"source":["%pip install pydicom"]},{"cell_type":"markdown","metadata":{},"source":["imports, initiating dataloaders"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3662,"status":"ok","timestamp":1710388660985,"user":{"displayName":"Haoyu Zhou","userId":"17886401950307679344"},"user_tz":-660},"id":"gZ4IgZNy7sVj"},"outputs":[],"source":["# imports\n","import datetime\n","import time\n","import warnings\n","import torch\n","import config\n","from dataio.dataloader import create_dataloader\n","from networks.resnet_classifier import resnet18_classifier\n","from training.evaluation import AccuracyEvaluator, LossEvaluator\n","from training.utility.progress_bar import ProgressBar\n","from training.utility.early_stopper import ValLoss as EarlyStopper\n","\n","# whenever possible, use cuda instead of cpu\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")\n","    warnings.warn(\"cuda is using CPU, this can be very slow\")\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# paths to save and load state dictionary\n","import os\n","import re\n","\n","load_sd = False\n","save_sd = True\n","\n","bin_path = \"bin\"\n","assert os.path.isdir(bin_path)\n","sd_files = [\n","    filename for filename in os.listdir(bin_path)\n","    if re.match(r'res18_state_[0-9]{2}-[0-9]{2}\\.pkl', filename)]\n","sd_files.sort(reverse=True)\n","sd_load_filename = sd_files[0] if len(sd_files) > 0 else None\n","sd_save_filename = f\"res18_state_{datetime.datetime.now().strftime('%m-%d')}.pkl\"\n","sd_load_path = os.path.join(bin_path, sd_load_filename) \\\n","    if sd_load_filename is not None else None\n","sd_save_path = os.path.join(bin_path, sd_save_filename)"]},{"cell_type":"markdown","metadata":{},"source":["preparing the training:\n","1. read dicoms and labels from configuration and tracking table, initiate dataloaders\n","2. set up criterions and optimizers, training parameters"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# reading from configurations\n","dicoms = config.tracking_table['dicom_path'].to_list()\n","labels = config.tracking_table['label'].astype('int16').to_list()\n","\n","# initiate the dataloaders\n","dataloader_dict = create_dataloader(\n","    dicoms, labels,\n","    dicom_dir = config.dicom_dir,\n","    batch_size = 1,\n","    validation_size = config.validation_size,\n","    test_size = config.test_size,\n","    img_size = (64, 64)\n",")\n","training_dataloader, validation_dataloader, test_dataloader = \\\n","    (dataloader_dict.get(key) for key in ('training_dataloader', 'validation_dataloader', 'test_dataloader'))"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":694,"status":"ok","timestamp":1710388665235,"user":{"displayName":"Haoyu Zhou","userId":"17886401950307679344"},"user_tz":-660},"id":"mNMjQKN57sVk"},"outputs":[],"source":["# some settings, move to config in future\n","learning_rate = 0.0001 # 0.00005, originally without lr scheduler\n","n_epoches = 15\n","starting_epoch = 0\n","\n","# the classifier model\n","model = resnet18_classifier\n","# load state dict into \n","if load_sd and sd_load_path:\n","    state_dict = torch.load(sd_load_path)\n","    model.load_state_dict(state_dict)\n","\n","# optimizers\n","loss_function = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","# scheduler = torch.optim.lr_scheduler.OneCycleLR(\n","#     optimizer, max_lr=learning_rate,\n","#     steps_per_epoch=len(training_dataloader), epochs=n_epoches,\n","#     )\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer, 'min', factor=0.25, patience=1,\n","    # threshold=0.05, threshold_mode='rel',\n","    min_lr = learning_rate / 32,\n","    cooldown=7,\n",")\n","earlystopper = EarlyStopper(tolerance=4, target=0.25)\n","\n","# accuracy and loss evaluators\n","training_loss = LossEvaluator(loss_function)\n","validation_loss = LossEvaluator(loss_function)\n","validation_accuracy = AccuracyEvaluator()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# to continue training for n_epoches\n","n_epoches = 10"]},{"cell_type":"markdown","metadata":{"id":"lj81jJj17sVl"},"source":["training for resnet18 image quality classifier"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch # 1\n","train loss: 0.022          validation loss: 0.508          validation accuracy: 80.36 %\n","precision: 1.0          recall: 0.25          f1: 0.4\n","duration: 31.11 s          learning rate: 0.0001\n","---------------------------------------------------------------------------\n","epoch # 2\n","train loss: 0.069          validation loss: 0.518          validation accuracy: 82.14 %\n","precision: 1.0          recall: 0.5          f1: 0.667\n","duration: 30.9 s          learning rate: 0.0001\n","---------------------------------------------------------------------------\n","epoch # 3\n","train loss: 0.11          validation loss: 0.508          validation accuracy: 85.71 %\n","precision: 1.0          recall: 1.0          f1: 1.0\n","duration: 30.59 s          learning rate: 0.0001\n","---------------------------------------------------------------------------\n","epoch # 4\n","train loss: 0.105          validation loss: 0.476          validation accuracy: 89.29 %\n","precision: 1.0          recall: 1.0          f1: 1.0\n","duration: 30.58 s          learning rate: 0.0001\n","---------------------------------------------------------------------------\n","epoch # 5\n","train loss: 0.086          validation loss: 0.484          validation accuracy: 82.14 %\n","precision: 1.0          recall: 0.5          f1: 0.667\n","duration: 31.41 s          learning rate: 0.0001\n","---------------------------------------------------------------------------\n","epoch # 6\n","train loss: 0.073          validation loss: 0.497          validation accuracy: 82.14 %\n","precision: 1.0          recall: 0.5          f1: 0.667\n","duration: 29.67 s          learning rate: 2.5e-05\n","---------------------------------------------------------------------------\n","epoch # 7\n","train loss: 0.063          validation loss: 0.508          validation accuracy: 82.14 %\n","precision: 1.0          recall: 0.5          f1: 0.667\n","duration: 29.88 s          learning rate: 2.5e-05\n","---------------------------------------------------------------------------\n","epoch # 8\n","train loss: 0.056          validation loss: 0.517          validation accuracy: 82.14 %\n","precision: 1.0          recall: 0.5          f1: 0.667\n","duration: 29.68 s          learning rate: 2.5e-05\n","---------------------------------------------------------------------------\n","epoch # 9\n","train loss: 0.05          validation loss: 0.525          validation accuracy: 82.14 %\n","precision: 1.0          recall: 0.5          f1: 0.667\n","duration: 29.81 s          learning rate: 2.5e-05\n","---------------------------------------------------------------------------\n","epoch # 10\n","train loss: 0.045          validation loss: 0.532          validation accuracy: 82.14 %\n","precision: 1.0          recall: 0.5          f1: 0.667\n","duration: 29.69 s          learning rate: 2.5e-05\n","---------------------------------------------------------------------------\n","epoch # 11\n","train loss: 0.041          validation loss: 0.539          validation accuracy: 82.14 %\n","precision: 1.0          recall: 0.5          f1: 0.667\n","duration: 29.81 s          learning rate: 2.5e-05\n","---------------------------------------------------------------------------\n","epoch # 12\n","train loss: 0.038          validation loss: 0.546          validation accuracy: 82.14 %\n","precision: 1.0          recall: 0.5          f1: 0.667\n","duration: 29.76 s          learning rate: 2.5e-05\n","---------------------------------------------------------------------------\n","epoch # 13\n","train loss: 0.035          validation loss: 0.552          validation accuracy: 82.14 %\n","precision: 1.0          recall: 0.5          f1: 0.667\n","duration: 29.69 s          learning rate: 2.5e-05\n","---------------------------------------------------------------------------\n","epoch # 14\n","train loss: 0.033          validation loss: 0.558          validation accuracy: 82.14 %\n","precision: 1.0          recall: 0.5          f1: 0.667\n","duration: 29.97 s          learning rate: 2.5e-05\n","---------------------------------------------------------------------------\n","epoch # 15\n","train loss: 0.031          validation loss: 0.564          validation accuracy: 82.14 %\n","precision: 1.0          recall: 0.5          f1: 0.667\n","duration: 29.67 s          learning rate: 6.25e-06\n","---------------------------------------------------------------------------\n","state dict saved to path: bin\\res18_state_03-28.pkl\n"]}],"source":["# evaluators for training/validation loss and accuracy\n","# training_loss = LossEvaluator(loss_function)\n","# validation_loss = LossEvaluator(loss_function)\n","# validation_accuracy = AccuracyEvaluator()\n","\n","# training epoches loop\n","for epoch in range(n_epoches):\n","    current_epoch = epoch + 1 + starting_epoch\n","    print(f'epoch # {current_epoch}')\n","    progress = ProgressBar(len(training_dataloader) + len(validation_dataloader))\n","    epoch_start_time = time.time()\n","    # reset pred and actual labels after each epoch\n","    validation_accuracy.reset()\n","    training_loss.reset()\n","    validation_loss.reset()\n","    # training network\n","    for images, labels in training_dataloader:\n","        # images = images.to(torch.float32)\n","        # labels = labels.to(torch.float32)\n","        labels_pred = model(images)\n","        # train loss\n","        loss_training = loss_function(labels_pred, labels)\n","        training_loss.append_loss(loss_training.item())\n","        # backpropagation\n","        optimizer.zero_grad()\n","        loss_training.backward()\n","        optimizer.step()\n","        progress.step()\n","    # validating network\n","    for images, labels in validation_dataloader:\n","        # images = images.to(torch.float32)\n","        # labels = labels.to(torch.float32)\n","        labels_pred = model(images)\n","        loss_validation = loss_function(labels_pred, labels)\n","        validation_loss.append_loss(loss_validation.item())\n","        validation_accuracy.append(labels_pred, labels)\n","        progress.step()\n","    epoch_end_time = time.time()\n","    print(\n","        f'train loss: {training_loss}  \\\n","        validation loss: {validation_loss}  \\\n","        validation accuracy: {validation_accuracy}')\n","    print(\n","        f'precision: {round(validation_accuracy.precision(), 3)}  \\\n","        recall: {round(validation_accuracy.recall(), 3)}  \\\n","        f1: {round(validation_accuracy.f1(), 3)}')\n","    # the evaluators have __str__\n","    print(\n","        f'duration: {round(epoch_end_time - epoch_start_time, 2)} s  \\\n","        learning rate: {round(scheduler.get_last_lr()[0], 9)}')\n","    # step scheduler\n","    scheduler.step(validation_loss.value())\n","    # step early stopper\n","    earlystopper.step(validation_loss.value())\n","    print('-'*75)\n","    if earlystopper.stop():\n","        print('early stopper triggered, break')\n","        break\n","    \n","\n","# update the starting epoch number\n","starting_epoch += epoch"]},{"cell_type":"markdown","metadata":{},"source":["save state dict"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# save model state_dicts to target path\n","if save_sd:\n","    torch.save(model.state_dict(), sd_save_path)\n","    print(f'state dict saved to path: {sd_save_path}')"]},{"cell_type":"markdown","metadata":{},"source":["*(debugging the network)*"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/plain":["980"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["len(validation_loss.labels_actual_raw)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["'bin/res18_state_03-28'"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["import datetime\n","state_dict_save_path = f\"bin/res18_state_{datetime.datetime.now().strftime('%m-%d')}\"\n","state_dict_save_path"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["import datetime\n","state_dict_save_path = f\"bin/res18_state_{datetime.datetime.now().strftime('%m-%d')}.pkl\"\n","torch.save(model.state_dict(), state_dict_save_path)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["(0, 0, 13, 0)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["validation_accuracy._tfpn()"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["140"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["sum([len(training_dataloader), len(validation_dataloader), len(test_dataloader)])"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["1"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["validation_pred_labels = [torch.argmax(lbl).item() for lbl in validation_accuracy.labels_pred_raw]\n","validation_actual_labels = [torch.argmax(lbl).item() for lbl in validation_accuracy.labels_actual_raw]\n","sum(validation_pred_labels)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["0.8520710059171598"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["n_total = len(validation_actual_labels)\n","n_correct = 0\n","for pred_label, actual_label in zip(validation_pred_labels, validation_actual_labels):\n","    if pred_label == actual_label:\n","        n_correct += 1\n","n_correct / n_total"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["[tensor([ 0.5962, -0.0964, -1.0432], grad_fn=<UnbindBackward0>),\n"," tensor([ 0.5093,  0.1406, -0.8743], grad_fn=<UnbindBackward0>),\n"," tensor([ 1.3376, -0.6933, -1.3025], grad_fn=<UnbindBackward0>)]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["validation_accuracy.labels_pred_raw[:3]"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["0.8520710059171598"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["validation_accuracy.accuracy()"]},{"cell_type":"markdown","metadata":{},"source":["calculate test set loss and accuracy"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["test loss: 0.649    test accuracy: 80.0 %\n","precision: 1.0      recall: 0.2      f1: 0.333\n"]}],"source":["# evaluators for test loss and accuracy\n","test_loss = LossEvaluator(criterion=loss_function)\n","test_accuracy = AccuracyEvaluator()\n","\n","# iterate through test dataloader\n","for images, labels in test_dataloader:\n","    images = images.to(torch.float32)\n","    labels = labels.to(torch.float32)\n","    labels_pred = model(images)\n","    loss = loss_function(labels_pred, labels)\n","    test_loss.append_loss(loss)\n","    test_accuracy.append(labels_pred, labels)\n","print(f'test loss: {test_loss}\\\n","    test accuracy: {test_accuracy}')\n","print(\n","    f'precision: {round(test_accuracy.precision(), 3)}  \\\n","    recall: {round(test_accuracy.recall(), 3)}  \\\n","    f1: {round(test_accuracy.f1(), 3)}')\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# function shows saliency map\n","def calculate_saliency_map(model, image, target_class):\n","\n","    \"\"\"\n","    Calculates the saliency map for a given image and target class.\n","\n","    Args:\n","    model: A PyTorch model.\n","    image: A PyTorch tensor containing the image.\n","    target_class: The target class.\n","\n","    Returns:\n","    numpy array containing the saliency map.\n","    \"\"\"\n","\n","    # Forward pass the image through the model.\n","    output = model(image)\n","    # Get the gradient of the output with respect to the input image.\n","    # gradient = torch.autograd.grad(output[0][target_class], image[0])\n","    gradient = torch.autograd.grad(\n","        output, image, grad_outputs=target_class.view(1,-1),\n","        allow_unused=True)[0][0]\n","    # Calculate the absolute value of the gradient.\n","    # saliency_map = torch.abs(gradient)\n","    saliency_map = torch.norm(gradient)\n","    # Normalize the saliency map.\n","    saliency_map = saliency_map / torch.max(saliency_map)\n","    saliency_map_np = saliency_map.detach().numpy()\n","    return saliency_map_np"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[-1.6480, -2.6376,  3.8333]], grad_fn=<AddmmBackward0>)"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["gradient = torch.autograd.grad(output, image, grad_outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","image = images[0][0]\n","plt.imshow(image, cmap='binary_r')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tempfile\n","for images in test_dataloader.view()"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/plain":["678"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["len(validation_accuracy.labels_actual_raw)"]},{"cell_type":"markdown","metadata":{},"source":["## Appendix\n","additional details about the model"]},{"cell_type":"markdown","metadata":{},"source":["structure of the resnet_18 model"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=3, bias=True)\n",")"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["isinstance(model, torch.nn.Module)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}
